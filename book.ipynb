{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d40c508",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# ðŸ† Jaguar Re-Identification Challenge - Complete Solution Notebook\n",
    "\n",
    "Below is a comprehensive, professional notebook for the Jaguar Re-Identification Challenge. I've structured it with clear sections, explanations, and visualizations.\n",
    "\n",
    "---\n",
    "\n",
    "## ðŸ“‹ Table of Contents\n",
    "\n",
    "1. [Introduction & Author Info](#1-introduction--author-info)\n",
    "2. [Environment Setup](#2-environment-setup)\n",
    "3. [Data Loading & Exploration](#3-data-loading--exploration)\n",
    "4. [Exploratory Data Analysis (EDA)](#4-exploratory-data-analysis-eda)\n",
    "5. [Data Preprocessing & Augmentation](#5-data-preprocessing--augmentation)\n",
    "6. [Model Architecture](#6-model-architecture)\n",
    "7. [Training Pipeline](#7-training-pipeline)\n",
    "8. [Inference & Embedding Generation](#8-inference--embedding-generation)\n",
    "9. [Submission Generation](#9-submission-generation)\n",
    "10. [Results Visualization](#10-results-visualization)\n",
    "11. [Conclusion](#11-conclusion)\n",
    "\n",
    "---\n",
    "\n",
    "## ðŸ“Š List of Plots & Visualizations\n",
    "\n",
    "| # | Plot Name | Description |\n",
    "|---|-----------|-------------|\n",
    "| 1 | Class Distribution Bar Plot | Shows number of images per jaguar identity |\n",
    "| 2 | Class Distribution Pie Chart | Percentage distribution of top jaguars |\n",
    "| 3 | Sample Images Grid | Display sample images for each jaguar |\n",
    "| 4 | Image Size Distribution | Histogram of image dimensions |\n",
    "| 5 | Image Aspect Ratio Distribution | Distribution of width/height ratios |\n",
    "| 6 | Sample Augmentations | Before/after augmentation examples |\n",
    "| 7 | Training Loss Curve | Loss progression during training |\n",
    "| 8 | Learning Rate Schedule | LR changes over epochs |\n",
    "| 9 | Validation Accuracy Curve | Accuracy progression |\n",
    "| 10 | t-SNE Embedding Visualization | 2D projection of jaguar embeddings |\n",
    "| 11 | UMAP Embedding Visualization | Alternative 2D embedding projection |\n",
    "| 12 | Similarity Distribution | Distribution of similarity scores |\n",
    "| 13 | Confusion Matrix Heatmap | Per-class prediction analysis |\n",
    "| 14 | Top Matches Visualization | Best matching pairs |\n",
    "| 15 | Hard Negatives Visualization | Most similar different jaguars |\n",
    "\n",
    "---\n",
    "\n",
    "```python\n",
    "# =============================================================================\n",
    "# CELL 1: INTRODUCTION & AUTHOR INFO\n",
    "# =============================================================================\n",
    "```\n",
    "\n",
    "```markdown\n",
    "# ðŸ† Jaguar Re-Identification Challenge\n",
    "\n",
    "## Competition Overview\n",
    "This notebook presents a comprehensive solution for the **Jaguar Re-Identification Challenge**, \n",
    "where we develop a computer vision model to identify individual jaguars from wildlife photographs.\n",
    "\n",
    "## Author Information\n",
    "\n",
    "### ðŸ‘¨â€ðŸ’» [YOUR NAME HERE]\n",
    "\n",
    "**Machine Learning Engineer | Data Scientist | AI Researcher**\n",
    "\n",
    "ðŸ“§ **Email:** your.email@example.com\n",
    "\n",
    "ðŸ”— **Social Networks:**\n",
    "- ðŸ’¼ [LinkedIn](https://www.linkedin.com/in/hammad-zahid-xyz/)\n",
    "- ðŸ™ [GitHub](https://github.com/Hamad-Ansari)\n",
    "- ðŸ¦ [Twitter/X](https://twitter.com/zahid_hamm57652)\n",
    "- ðŸ“Š [Kaggle](https://www.kaggle.com/hammadansari7)\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "### ðŸŽ¯ Approach Summary:\n",
    "1. **Backbone:** EfficientNet-B4 / ConvNeXt with pretrained weights\n",
    "2. **Loss Function:** ArcFace Loss for metric learning\n",
    "3. **Data Augmentation:** Heavy augmentation to handle intra-class variation\n",
    "4. **Handling Imbalance:** Weighted sampling + Focal Loss\n",
    "5. **Inference:** Cosine similarity between embeddings\n",
    "\n",
    "---\n",
    "```\n",
    "\n",
    "```python\n",
    "# =============================================================================\n",
    "# CELL 2: ENVIRONMENT SETUP & IMPORTS\n",
    "# =============================================================================\n",
    "\"\"\"\n",
    "Environment Setup - Installing and importing all necessary libraries\n",
    "\"\"\"\n",
    "\n",
    "# Install required packages (uncomment if needed)\n",
    "# !pip install -q torch torchvision timm albumentations\n",
    "# !pip install -q pytorch-metric-learning\n",
    "# !pip install -q umap-learn\n",
    "# !pip install -q wandb\n",
    "# !pip install -q tqdm matplotlib seaborn pandas numpy scikit-learn\n",
    "# !pip install -q opencv-python-headless pillow\n",
    "\n",
    "import os\n",
    "import gc\n",
    "import random\n",
    "import warnings\n",
    "from pathlib import Path\n",
    "from typing import Dict, List, Tuple, Optional\n",
    "from collections import Counter\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from PIL import Image\n",
    "import cv2\n",
    "\n",
    "# PyTorch imports\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader, WeightedRandomSampler\n",
    "from torch.optim import AdamW\n",
    "from torch.optim.lr_scheduler import CosineAnnealingWarmRestarts, OneCycleLR\n",
    "from torch.cuda.amp import GradScaler, autocast\n",
    "\n",
    "# Torchvision\n",
    "import torchvision.transforms as T\n",
    "from torchvision import models\n",
    "\n",
    "# Timm for pretrained models\n",
    "import timm\n",
    "\n",
    "# Albumentations for augmentation\n",
    "import albumentations as A\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "\n",
    "# Sklearn utilities\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.metrics import average_precision_score\n",
    "\n",
    "# Progress bar\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "# Suppress warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set random seeds for reproducibility\n",
    "def set_seed(seed: int = 42):\n",
    "    \"\"\"Set random seeds for reproducibility\"\"\"\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "\n",
    "set_seed(42)\n",
    "\n",
    "# Device configuration\n",
    "DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"ðŸ”§ Using device: {DEVICE}\")\n",
    "print(f\"ðŸ Python version: {os.sys.version}\")\n",
    "print(f\"ðŸ”¥ PyTorch version: {torch.__version__}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"ðŸŽ® GPU: {torch.cuda.get_device_name(0)}\")\n",
    "    print(f\"ðŸ’¾ GPU Memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.2f} GB\")\n",
    "```\n",
    "\n",
    "```python\n",
    "# =============================================================================\n",
    "# CELL 3: CONFIGURATION\n",
    "# =============================================================================\n",
    "\"\"\"\n",
    "Configuration - All hyperparameters and paths in one place\n",
    "\"\"\"\n",
    "\n",
    "class CFG:\n",
    "    \"\"\"Configuration class for all hyperparameters\"\"\"\n",
    "    \n",
    "    # Paths\n",
    "    BASE_PATH = Path(\"./\")  # Update this to your data directory\n",
    "    TRAIN_DIR = BASE_PATH / \"train\"\n",
    "    TEST_DIR = BASE_PATH / \"test\"\n",
    "    TRAIN_CSV = BASE_PATH / \"train.csv\"\n",
    "    TEST_CSV = BASE_PATH / \"test.csv\"\n",
    "    SAMPLE_SUB = BASE_PATH / \"sample_submission.csv\"\n",
    "    OUTPUT_DIR = BASE_PATH / \"outputs\"\n",
    "    \n",
    "    # Model\n",
    "    MODEL_NAME = \"tf_efficientnet_b4_ns\"  # Options: convnext_base, efficientnet_b4, etc.\n",
    "    PRETRAINED = True\n",
    "    EMBEDDING_DIM = 512\n",
    "    NUM_CLASSES = 31  # Number of unique jaguars\n",
    "    \n",
    "    # Training\n",
    "    EPOCHS = 30\n",
    "    BATCH_SIZE = 16\n",
    "    ACCUMULATION_STEPS = 2\n",
    "    LEARNING_RATE = 1e-4\n",
    "    WEIGHT_DECAY = 1e-4\n",
    "    WARMUP_EPOCHS = 3\n",
    "    \n",
    "    # ArcFace parameters\n",
    "    ARCFACE_S = 30.0  # Scale\n",
    "    ARCFACE_M = 0.5   # Margin\n",
    "    \n",
    "    # Image\n",
    "    IMG_SIZE = 384\n",
    "    NUM_WORKERS = 4\n",
    "    \n",
    "    # Augmentation\n",
    "    AUGMENT_PROB = 0.5\n",
    "    \n",
    "    # Cross-validation\n",
    "    N_FOLDS = 5\n",
    "    SELECTED_FOLDS = [0]  # Which folds to train\n",
    "    \n",
    "    # Misc\n",
    "    SEED = 42\n",
    "    MIXED_PRECISION = True\n",
    "    DEBUG = False  # Set to True for quick debugging\n",
    "    \n",
    "    @classmethod\n",
    "    def display(cls):\n",
    "        \"\"\"Display all configuration parameters\"\"\"\n",
    "        print(\"=\" * 60)\n",
    "        print(\"ðŸ“‹ CONFIGURATION\")\n",
    "        print(\"=\" * 60)\n",
    "        for key, value in vars(cls).items():\n",
    "            if not key.startswith('_') and not callable(value):\n",
    "                print(f\"  {key}: {value}\")\n",
    "        print(\"=\" * 60)\n",
    "\n",
    "# Create output directory\n",
    "CFG.OUTPUT_DIR.mkdir(exist_ok=True, parents=True)\n",
    "\n",
    "# Display configuration\n",
    "CFG.display()\n",
    "```\n",
    "\n",
    "```python\n",
    "# =============================================================================\n",
    "# CELL 4: DATA LOADING\n",
    "# =============================================================================\n",
    "\"\"\"\n",
    "Data Loading - Load and examine the dataset files\n",
    "\"\"\"\n",
    "\n",
    "# Load CSV files\n",
    "train_df = pd.read_csv(CFG.TRAIN_CSV)\n",
    "test_df = pd.read_csv(CFG.TEST_CSV)\n",
    "sample_sub = pd.read_csv(CFG.SAMPLE_SUB)\n",
    "\n",
    "print(\"ðŸ“ Data Loaded Successfully!\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Display basic info\n",
    "print(\"\\nðŸ“Š TRAIN DATA:\")\n",
    "print(f\"  Shape: {train_df.shape}\")\n",
    "print(f\"  Columns: {list(train_df.columns)}\")\n",
    "print(f\"  Unique Jaguars: {train_df['ground_truth'].nunique()}\")\n",
    "print(f\"\\n  Sample rows:\")\n",
    "display(train_df.head(10))\n",
    "\n",
    "print(\"\\nðŸ“Š TEST DATA:\")\n",
    "print(f\"  Shape: {test_df.shape}\")\n",
    "print(f\"  Columns: {list(test_df.columns)}\")\n",
    "print(f\"  Unique Query Images: {test_df['query_image'].nunique()}\")\n",
    "print(f\"  Unique Gallery Images: {test_df['gallery_image'].nunique()}\")\n",
    "print(f\"\\n  Sample rows:\")\n",
    "display(test_df.head(10))\n",
    "\n",
    "print(\"\\nðŸ“Š SAMPLE SUBMISSION:\")\n",
    "print(f\"  Shape: {sample_sub.shape}\")\n",
    "print(f\"  Columns: {list(sample_sub.columns)}\")\n",
    "print(f\"\\n  Sample rows:\")\n",
    "display(sample_sub.head(10))\n",
    "```\n",
    "\n",
    "```python\n",
    "# =============================================================================\n",
    "# CELL 5: EXPLORATORY DATA ANALYSIS (EDA)\n",
    "# =============================================================================\n",
    "\"\"\"\n",
    "Exploratory Data Analysis - Understanding the dataset through visualizations\n",
    "\"\"\"\n",
    "\n",
    "# Create figure with subplots\n",
    "fig = plt.figure(figsize=(20, 16))\n",
    "\n",
    "# ============================================================================\n",
    "# PLOT 1: Class Distribution Bar Plot\n",
    "# ============================================================================\n",
    "ax1 = fig.add_subplot(2, 2, 1)\n",
    "class_counts = train_df['ground_truth'].value_counts()\n",
    "\n",
    "colors = plt.cm.viridis(np.linspace(0, 1, len(class_counts)))\n",
    "bars = ax1.barh(class_counts.index, class_counts.values, color=colors)\n",
    "ax1.set_xlabel('Number of Images', fontsize=12)\n",
    "ax1.set_ylabel('Jaguar Identity', fontsize=12)\n",
    "ax1.set_title('ðŸ“Š Plot 1: Class Distribution - Images per Jaguar', fontsize=14, fontweight='bold')\n",
    "ax1.invert_yaxis()\n",
    "\n",
    "# Add value labels\n",
    "for bar, val in zip(bars, class_counts.values):\n",
    "    ax1.text(val + 1, bar.get_y() + bar.get_height()/2, str(val), \n",
    "             va='center', fontsize=9)\n",
    "\n",
    "# ============================================================================\n",
    "# PLOT 2: Class Distribution Pie Chart (Top 10)\n",
    "# ============================================================================\n",
    "ax2 = fig.add_subplot(2, 2, 2)\n",
    "top_10 = class_counts.head(10)\n",
    "others = class_counts.iloc[10:].sum()\n",
    "pie_data = list(top_10.values) + [others]\n",
    "pie_labels = list(top_10.index) + ['Others']\n",
    "\n",
    "colors_pie = plt.cm.Set3(np.linspace(0, 1, len(pie_data)))\n",
    "wedges, texts, autotexts = ax2.pie(pie_data, labels=pie_labels, autopct='%1.1f%%',\n",
    "                                    colors=colors_pie, pctdistance=0.8)\n",
    "ax2.set_title('ðŸ“Š Plot 2: Top 10 Jaguars Distribution', fontsize=14, fontweight='bold')\n",
    "\n",
    "# ============================================================================\n",
    "# PLOT 3: Class Imbalance Analysis\n",
    "# ============================================================================\n",
    "ax3 = fig.add_subplot(2, 2, 3)\n",
    "\n",
    "# Calculate imbalance metrics\n",
    "min_count = class_counts.min()\n",
    "max_count = class_counts.max()\n",
    "mean_count = class_counts.mean()\n",
    "median_count = class_counts.median()\n",
    "\n",
    "stats_text = f\"\"\"\n",
    "ðŸ“ˆ Dataset Statistics:\n",
    "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "Total Images: {len(train_df):,}\n",
    "Total Jaguars: {len(class_counts)}\n",
    "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "Min Images/Class: {min_count}\n",
    "Max Images/Class: {max_count}\n",
    "Mean: {mean_count:.1f}\n",
    "Median: {median_count:.1f}\n",
    "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "Imbalance Ratio: {max_count/min_count:.1f}x\n",
    "\"\"\"\n",
    "\n",
    "ax3.text(0.1, 0.5, stats_text, transform=ax3.transAxes, fontsize=14,\n",
    "         verticalalignment='center', fontfamily='monospace',\n",
    "         bbox=dict(boxstyle='round', facecolor='lightblue', alpha=0.8))\n",
    "ax3.axis('off')\n",
    "ax3.set_title('ðŸ“Š Plot 3: Dataset Statistics', fontsize=14, fontweight='bold')\n",
    "\n",
    "# ============================================================================\n",
    "# PLOT 4: Distribution Histogram\n",
    "# ============================================================================\n",
    "ax4 = fig.add_subplot(2, 2, 4)\n",
    "ax4.hist(class_counts.values, bins=15, color='steelblue', edgecolor='black', alpha=0.7)\n",
    "ax4.axvline(mean_count, color='red', linestyle='--', linewidth=2, label=f'Mean: {mean_count:.1f}')\n",
    "ax4.axvline(median_count, color='green', linestyle='--', linewidth=2, label=f'Median: {median_count:.1f}')\n",
    "ax4.set_xlabel('Number of Images', fontsize=12)\n",
    "ax4.set_ylabel('Number of Jaguars', fontsize=12)\n",
    "ax4.set_title('ðŸ“Š Plot 4: Distribution of Images per Jaguar', fontsize=14, fontweight='bold')\n",
    "ax4.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(CFG.OUTPUT_DIR / 'eda_class_distribution.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nâœ… Plot saved to:\", CFG.OUTPUT_DIR / 'eda_class_distribution.png')\n",
    "```\n",
    "\n",
    "```python\n",
    "# =============================================================================\n",
    "# CELL 6: SAMPLE IMAGES VISUALIZATION\n",
    "# =============================================================================\n",
    "\"\"\"\n",
    "Visualize sample images for each jaguar identity\n",
    "\"\"\"\n",
    "\n",
    "def load_image(path: Path) -> np.ndarray:\n",
    "    \"\"\"Load an image and convert to RGB\"\"\"\n",
    "    img = Image.open(path).convert('RGB')\n",
    "    return np.array(img)\n",
    "\n",
    "def plot_sample_images(df: pd.DataFrame, img_dir: Path, n_samples: int = 3):\n",
    "    \"\"\"\n",
    "    ðŸ“Š Plot 5: Sample Images Grid\n",
    "    Display sample images for each jaguar identity\n",
    "    \"\"\"\n",
    "    unique_jaguars = df['ground_truth'].unique()\n",
    "    n_jaguars = len(unique_jaguars)\n",
    "    \n",
    "    fig, axes = plt.subplots(n_jaguars, n_samples, figsize=(4*n_samples, 3*n_jaguars))\n",
    "    fig.suptitle('ðŸ“Š Plot 5: Sample Images for Each Jaguar Identity', \n",
    "                 fontsize=16, fontweight='bold', y=1.02)\n",
    "    \n",
    "    for i, jaguar in enumerate(sorted(unique_jaguars)):\n",
    "        jaguar_images = df[df['ground_truth'] == jaguar]['filename'].values\n",
    "        sample_images = jaguar_images[:n_samples]\n",
    "        \n",
    "        for j in range(n_samples):\n",
    "            ax = axes[i, j] if n_jaguars > 1 else axes[j]\n",
    "            \n",
    "            if j < len(sample_images):\n",
    "                img_path = img_dir / sample_images[j]\n",
    "                if img_path.exists():\n",
    "                    img = load_image(img_path)\n",
    "                    ax.imshow(img)\n",
    "                    ax.set_title(f'{jaguar}' if j == 0 else '', fontsize=10)\n",
    "                else:\n",
    "                    ax.text(0.5, 0.5, 'Image\\nNot Found', ha='center', va='center')\n",
    "            else:\n",
    "                ax.text(0.5, 0.5, 'No More\\nImages', ha='center', va='center')\n",
    "            \n",
    "            ax.axis('off')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig(CFG.OUTPUT_DIR / 'sample_images_grid.png', dpi=100, bbox_inches='tight')\n",
    "    plt.show()\n",
    "\n",
    "# Show sample images (limit to first 10 jaguars for display)\n",
    "sample_df = train_df[train_df['ground_truth'].isin(train_df['ground_truth'].unique()[:10])]\n",
    "plot_sample_images(sample_df, CFG.TRAIN_DIR, n_samples=4)\n",
    "```\n",
    "\n",
    "```python\n",
    "# =============================================================================\n",
    "# CELL 7: IMAGE PROPERTIES ANALYSIS\n",
    "# =============================================================================\n",
    "\"\"\"\n",
    "Analyze image properties like size, aspect ratio, and file sizes\n",
    "\"\"\"\n",
    "\n",
    "def analyze_image_properties(df: pd.DataFrame, img_dir: Path, sample_size: int = 200):\n",
    "    \"\"\"\n",
    "    Analyze image properties\n",
    "    \"\"\"\n",
    "    widths, heights, aspect_ratios, file_sizes = [], [], [], []\n",
    "    \n",
    "    sample_files = df['filename'].sample(min(sample_size, len(df))).values\n",
    "    \n",
    "    for filename in tqdm(sample_files, desc=\"Analyzing images\"):\n",
    "        img_path = img_dir / filename\n",
    "        if img_path.exists():\n",
    "            img = Image.open(img_path)\n",
    "            w, h = img.size\n",
    "            widths.append(w)\n",
    "            heights.append(h)\n",
    "            aspect_ratios.append(w / h)\n",
    "            file_sizes.append(os.path.getsize(img_path) / 1024)  # KB\n",
    "    \n",
    "    return widths, heights, aspect_ratios, file_sizes\n",
    "\n",
    "# Analyze training images\n",
    "print(\"ðŸ“Š Analyzing image properties...\")\n",
    "widths, heights, aspect_ratios, file_sizes = analyze_image_properties(train_df, CFG.TRAIN_DIR)\n",
    "\n",
    "# Create visualization\n",
    "fig, axes = plt.subplots(2, 2, figsize=(14, 10))\n",
    "\n",
    "# ============================================================================\n",
    "# PLOT 6: Image Width Distribution\n",
    "# ============================================================================\n",
    "ax1 = axes[0, 0]\n",
    "ax1.hist(widths, bins=30, color='coral', edgecolor='black', alpha=0.7)\n",
    "ax1.axvline(np.mean(widths), color='red', linestyle='--', linewidth=2, \n",
    "            label=f'Mean: {np.mean(widths):.0f}')\n",
    "ax1.set_xlabel('Width (pixels)')\n",
    "ax1.set_ylabel('Frequency')\n",
    "ax1.set_title('ðŸ“Š Plot 6: Image Width Distribution', fontweight='bold')\n",
    "ax1.legend()\n",
    "\n",
    "# ============================================================================\n",
    "# PLOT 7: Image Height Distribution\n",
    "# ============================================================================\n",
    "ax2 = axes[0, 1]\n",
    "ax2.hist(heights, bins=30, color='lightgreen', edgecolor='black', alpha=0.7)\n",
    "ax2.axvline(np.mean(heights), color='green', linestyle='--', linewidth=2,\n",
    "            label=f'Mean: {np.mean(heights):.0f}')\n",
    "ax2.set_xlabel('Height (pixels)')\n",
    "ax2.set_ylabel('Frequency')\n",
    "ax2.set_title('ðŸ“Š Plot 7: Image Height Distribution', fontweight='bold')\n",
    "ax2.legend()\n",
    "\n",
    "# ============================================================================\n",
    "# PLOT 8: Aspect Ratio Distribution\n",
    "# ============================================================================\n",
    "ax3 = axes[1, 0]\n",
    "ax3.hist(aspect_ratios, bins=30, color='skyblue', edgecolor='black', alpha=0.7)\n",
    "ax3.axvline(1.0, color='red', linestyle='--', linewidth=2, label='Square (1:1)')\n",
    "ax3.set_xlabel('Aspect Ratio (Width/Height)')\n",
    "ax3.set_ylabel('Frequency')\n",
    "ax3.set_title('ðŸ“Š Plot 8: Aspect Ratio Distribution', fontweight='bold')\n",
    "ax3.legend()\n",
    "\n",
    "# ============================================================================\n",
    "# PLOT 9: File Size Distribution\n",
    "# ============================================================================\n",
    "ax4 = axes[1, 1]\n",
    "ax4.hist(file_sizes, bins=30, color='plum', edgecolor='black', alpha=0.7)\n",
    "ax4.axvline(np.mean(file_sizes), color='purple', linestyle='--', linewidth=2,\n",
    "            label=f'Mean: {np.mean(file_sizes):.0f} KB')\n",
    "ax4.set_xlabel('File Size (KB)')\n",
    "ax4.set_ylabel('Frequency')\n",
    "ax4.set_title('ðŸ“Š Plot 9: File Size Distribution', fontweight='bold')\n",
    "ax4.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(CFG.OUTPUT_DIR / 'image_properties.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "# Print statistics\n",
    "print(\"\\nðŸ“ˆ Image Property Statistics:\")\n",
    "print(f\"  Width:  Min={min(widths)}, Max={max(widths)}, Mean={np.mean(widths):.0f}\")\n",
    "print(f\"  Height: Min={min(heights)}, Max={max(heights)}, Mean={np.mean(heights):.0f}\")\n",
    "print(f\"  Aspect Ratio: Min={min(aspect_ratios):.2f}, Max={max(aspect_ratios):.2f}\")\n",
    "print(f\"  File Size: Min={min(file_sizes):.0f}KB, Max={max(file_sizes):.0f}KB\")\n",
    "```\n",
    "\n",
    "```python\n",
    "# =============================================================================\n",
    "# CELL 8: DATA PREPROCESSING - LABEL ENCODING\n",
    "# =============================================================================\n",
    "\"\"\"\n",
    "Encode labels and prepare data for training\n",
    "\"\"\"\n",
    "\n",
    "# Initialize Label Encoder\n",
    "label_encoder = LabelEncoder()\n",
    "train_df['label'] = label_encoder.fit_transform(train_df['ground_truth'])\n",
    "\n",
    "# Create mapping dictionaries\n",
    "label_to_jaguar = dict(zip(range(len(label_encoder.classes_)), label_encoder.classes_))\n",
    "jaguar_to_label = dict(zip(label_encoder.classes_, range(len(label_encoder.classes_))))\n",
    "\n",
    "print(\"ðŸ·ï¸ Label Encoding Complete!\")\n",
    "print(f\"  Number of classes: {len(label_encoder.classes_)}\")\n",
    "print(\"\\nðŸ“‹ Label Mapping:\")\n",
    "for label, jaguar in sorted(label_to_jaguar.items()):\n",
    "    count = len(train_df[train_df['label'] == label])\n",
    "    print(f\"  {label:2d} â†’ {jaguar:15s} ({count:3d} images)\")\n",
    "\n",
    "# Add full path\n",
    "train_df['image_path'] = train_df['filename'].apply(lambda x: str(CFG.TRAIN_DIR / x))\n",
    "\n",
    "# Display updated dataframe\n",
    "print(\"\\nðŸ“Š Updated Training DataFrame:\")\n",
    "display(train_df.head(10))\n",
    "```\n",
    "\n",
    "```python\n",
    "# =============================================================================\n",
    "# CELL 9: DATA AUGMENTATION\n",
    "# =============================================================================\n",
    "\"\"\"\n",
    "Define data augmentation pipelines for training and validation\n",
    "\"\"\"\n",
    "\n",
    "def get_train_transforms(img_size: int = 384):\n",
    "    \"\"\"\n",
    "    Training augmentation pipeline with heavy augmentation\n",
    "    to handle intra-class variation\n",
    "    \"\"\"\n",
    "    return A.Compose([\n",
    "        # Resize\n",
    "        A.LongestMaxSize(max_size=img_size),\n",
    "        A.PadIfNeeded(min_height=img_size, min_width=img_size, \n",
    "                      border_mode=cv2.BORDER_CONSTANT, value=0),\n",
    "        \n",
    "        # Geometric transforms\n",
    "        A.HorizontalFlip(p=0.5),\n",
    "        A.ShiftScaleRotate(shift_limit=0.1, scale_limit=0.2, rotate_limit=15, p=0.5),\n",
    "        A.Perspective(scale=(0.02, 0.05), p=0.3),\n",
    "        \n",
    "        # Color transforms\n",
    "        A.OneOf([\n",
    "            A.RandomBrightnessContrast(brightness_limit=0.2, contrast_limit=0.2, p=1),\n",
    "            A.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.1, p=1),\n",
    "            A.HueSaturationValue(hue_shift_limit=10, sat_shift_limit=20, val_shift_limit=20, p=1),\n",
    "        ], p=0.5),\n",
    "        \n",
    "        # Noise and blur\n",
    "        A.OneOf([\n",
    "            A.GaussNoise(var_limit=(10.0, 50.0), p=1),\n",
    "            A.ISONoise(color_shift=(0.01, 0.05), intensity=(0.1, 0.5), p=1),\n",
    "        ], p=0.3),\n",
    "        \n",
    "        A.OneOf([\n",
    "            A.MotionBlur(blur_limit=5, p=1),\n",
    "            A.GaussianBlur(blur_limit=5, p=1),\n",
    "        ], p=0.2),\n",
    "        \n",
    "        # Cutout/dropout\n",
    "        A.CoarseDropout(max_holes=8, max_height=img_size//16, max_width=img_size//16,\n",
    "                        min_holes=1, min_height=img_size//32, min_width=img_size//32,\n",
    "                        fill_value=0, p=0.3),\n",
    "        \n",
    "        # Normalize and convert\n",
    "        A.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "        ToTensorV2(),\n",
    "    ])\n",
    "\n",
    "def get_valid_transforms(img_size: int = 384):\n",
    "    \"\"\"\n",
    "    Validation transform pipeline (minimal augmentation)\n",
    "    \"\"\"\n",
    "    return A.Compose([\n",
    "        A.LongestMaxSize(max_size=img_size),\n",
    "        A.PadIfNeeded(min_height=img_size, min_width=img_size,\n",
    "                      border_mode=cv2.BORDER_CONSTANT, value=0),\n",
    "        A.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "        ToTensorV2(),\n",
    "    ])\n",
    "\n",
    "def get_test_transforms(img_size: int = 384):\n",
    "    \"\"\"\n",
    "    Test time augmentation (same as validation)\n",
    "    \"\"\"\n",
    "    return get_valid_transforms(img_size)\n",
    "\n",
    "# Visualize augmentations\n",
    "def visualize_augmentations(df: pd.DataFrame, img_dir: Path, n_samples: int = 4):\n",
    "    \"\"\"\n",
    "    ðŸ“Š Plot 10: Sample Augmentations\n",
    "    Show original and augmented images side by side\n",
    "    \"\"\"\n",
    "    fig, axes = plt.subplots(n_samples, 5, figsize=(20, 4*n_samples))\n",
    "    fig.suptitle('ðŸ“Š Plot 10: Data Augmentation Examples\\n(Original â†’ Augmented Versions)', \n",
    "                 fontsize=16, fontweight='bold', y=1.02)\n",
    "    \n",
    "    transform = get_train_transforms(CFG.IMG_SIZE)\n",
    "    sample_files = df['filename'].sample(n_samples).values\n",
    "    \n",
    "    for i, filename in enumerate(sample_files):\n",
    "        img_path = img_dir / filename\n",
    "        if img_path.exists():\n",
    "            img = cv2.imread(str(img_path))\n",
    "            img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "            \n",
    "            # Original\n",
    "            axes[i, 0].imshow(img)\n",
    "            axes[i, 0].set_title('Original' if i == 0 else '')\n",
    "            axes[i, 0].axis('off')\n",
    "            \n",
    "            # Augmented versions\n",
    "            for j in range(1, 5):\n",
    "                augmented = transform(image=img)['image']\n",
    "                # Denormalize for visualization\n",
    "                aug_img = augmented.permute(1, 2, 0).numpy()\n",
    "                aug_img = aug_img * np.array([0.229, 0.224, 0.225]) + np.array([0.485, 0.456, 0.406])\n",
    "                aug_img = np.clip(aug_img, 0, 1)\n",
    "                \n",
    "                axes[i, j].imshow(aug_img)\n",
    "                axes[i, j].set_title(f'Augmented {j}' if i == 0 else '')\n",
    "                axes[i, j].axis('off')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig(CFG.OUTPUT_DIR / 'augmentation_samples.png', dpi=150, bbox_inches='tight')\n",
    "    plt.show()\n",
    "\n",
    "# Visualize augmentations\n",
    "visualize_augmentations(train_df, CFG.TRAIN_DIR, n_samples=4)\n",
    "```\n",
    "\n",
    "```python\n",
    "# =============================================================================\n",
    "# CELL 10: CUSTOM DATASET CLASS\n",
    "# =============================================================================\n",
    "\"\"\"\n",
    "PyTorch Dataset for Jaguar Re-Identification\n",
    "\"\"\"\n",
    "\n",
    "class JaguarDataset(Dataset):\n",
    "    \"\"\"\n",
    "    Custom Dataset for Jaguar Re-Identification\n",
    "    \"\"\"\n",
    "    def __init__(\n",
    "        self, \n",
    "        df: pd.DataFrame, \n",
    "        img_dir: Path,\n",
    "        transform=None,\n",
    "        is_test: bool = False\n",
    "    ):\n",
    "        self.df = df.reset_index(drop=True)\n",
    "        self.img_dir = img_dir\n",
    "        self.transform = transform\n",
    "        self.is_test = is_test\n",
    "        \n",
    "        if not is_test:\n",
    "            self.labels = self.df['label'].values\n",
    "            self.filenames = self.df['filename'].values\n",
    "        else:\n",
    "            self.filenames = df['filename'].values if 'filename' in df.columns else df.values\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.filenames)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        filename = self.filenames[idx]\n",
    "        img_path = self.img_dir / filename\n",
    "        \n",
    "        # Load image\n",
    "        image = cv2.imread(str(img_path))\n",
    "        if image is None:\n",
    "            # Handle missing images with a black image\n",
    "            image = np.zeros((CFG.IMG_SIZE, CFG.IMG_SIZE, 3), dtype=np.uint8)\n",
    "        else:\n",
    "            image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "        \n",
    "        # Apply transforms\n",
    "        if self.transform:\n",
    "            image = self.transform(image=image)['image']\n",
    "        \n",
    "        if self.is_test:\n",
    "            return image, filename\n",
    "        else:\n",
    "            label = self.labels[idx]\n",
    "            return image, label\n",
    "    \n",
    "    def get_labels(self):\n",
    "        \"\"\"Return labels for weighted sampler\"\"\"\n",
    "        return self.labels\n",
    "\n",
    "\n",
    "class JaguarTestDataset(Dataset):\n",
    "    \"\"\"\n",
    "    Dataset for test images (inference only)\n",
    "    \"\"\"\n",
    "    def __init__(self, image_files: List[str], img_dir: Path, transform=None):\n",
    "        self.image_files = sorted(list(set(image_files)))\n",
    "        self.img_dir = img_dir\n",
    "        self.transform = transform\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.image_files)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        filename = self.image_files[idx]\n",
    "        img_path = self.img_dir / filename\n",
    "        \n",
    "        image = cv2.imread(str(img_path))\n",
    "        if image is None:\n",
    "            image = np.zeros((CFG.IMG_SIZE, CFG.IMG_SIZE, 3), dtype=np.uint8)\n",
    "        else:\n",
    "            image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "        \n",
    "        if self.transform:\n",
    "            image = self.transform(image=image)['image']\n",
    "        \n",
    "        return image, filename\n",
    "\n",
    "print(\"âœ… Dataset classes defined successfully!\")\n",
    "```\n",
    "\n",
    "```python\n",
    "# =============================================================================\n",
    "# CELL 11: ARCFACE LOSS IMPLEMENTATION\n",
    "# =============================================================================\n",
    "\"\"\"\n",
    "ArcFace Loss for Metric Learning\n",
    "Ref: https://arxiv.org/abs/1801.07698\n",
    "\"\"\"\n",
    "\n",
    "class ArcMarginProduct(nn.Module):\n",
    "    \"\"\"\n",
    "    ArcFace: Additive Angular Margin Loss for Deep Face Recognition\n",
    "    \n",
    "    Implementation of ArcFace loss which improves discriminability of embeddings\n",
    "    by adding an angular margin to the softmax loss.\n",
    "    \"\"\"\n",
    "    def __init__(\n",
    "        self, \n",
    "        in_features: int, \n",
    "        out_features: int, \n",
    "        s: float = 30.0, \n",
    "        m: float = 0.50,\n",
    "        easy_margin: bool = False\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.in_features = in_features\n",
    "        self.out_features = out_features\n",
    "        self.s = s\n",
    "        self.m = m\n",
    "        self.easy_margin = easy_margin\n",
    "        \n",
    "        # Initialize weights\n",
    "        self.weight = nn.Parameter(torch.FloatTensor(out_features, in_features))\n",
    "        nn.init.xavier_uniform_(self.weight)\n",
    "        \n",
    "        # Precompute values\n",
    "        self.cos_m = np.cos(m)\n",
    "        self.sin_m = np.sin(m)\n",
    "        self.th = np.cos(np.pi - m)\n",
    "        self.mm = np.sin(np.pi - m) * m\n",
    "        \n",
    "    def forward(self, input: torch.Tensor, label: torch.Tensor) -> torch.Tensor:\n",
    "        # Normalize features and weights\n",
    "        cosine = F.linear(F.normalize(input), F.normalize(self.weight))\n",
    "        sine = torch.sqrt(1.0 - torch.pow(cosine, 2).clamp(0, 1))\n",
    "        \n",
    "        # cos(theta + m)\n",
    "        phi = cosine * self.cos_m - sine * self.sin_m\n",
    "        \n",
    "        if self.easy_margin:\n",
    "            phi = torch.where(cosine > 0, phi, cosine)\n",
    "        else:\n",
    "            phi = torch.where(cosine > self.th, phi, cosine - self.mm)\n",
    "        \n",
    "        # One-hot encoding\n",
    "        one_hot = torch.zeros_like(cosine)\n",
    "        one_hot.scatter_(1, label.view(-1, 1).long(), 1)\n",
    "        \n",
    "        # Apply margin to target class\n",
    "        output = (one_hot * phi) + ((1.0 - one_hot) * cosine)\n",
    "        output *= self.s\n",
    "        \n",
    "        return output\n",
    "\n",
    "\n",
    "class FocalLoss(nn.Module):\n",
    "    \"\"\"\n",
    "    Focal Loss for handling class imbalance\n",
    "    Ref: https://arxiv.org/abs/1708.02002\n",
    "    \"\"\"\n",
    "    def __init__(self, gamma: float = 2.0, alpha: Optional[torch.Tensor] = None):\n",
    "        super().__init__()\n",
    "        self.gamma = gamma\n",
    "        self.alpha = alpha\n",
    "        \n",
    "    def forward(self, input: torch.Tensor, target: torch.Tensor) -> torch.Tensor:\n",
    "        ce_loss = F.cross_entropy(input, target, reduction='none')\n",
    "        pt = torch.exp(-ce_loss)\n",
    "        focal_loss = ((1 - pt) ** self.gamma) * ce_loss\n",
    "        \n",
    "        if self.alpha is not None:\n",
    "            alpha_t = self.alpha[target]\n",
    "            focal_loss = alpha_t * focal_loss\n",
    "        \n",
    "        return focal_loss.mean()\n",
    "\n",
    "print(\"âœ… ArcFace and Focal Loss implemented!\")\n",
    "```\n",
    "\n",
    "```python\n",
    "# =============================================================================\n",
    "# CELL 12: MODEL ARCHITECTURE\n",
    "# =============================================================================\n",
    "\"\"\"\n",
    "Jaguar Re-ID Model with Pretrained Backbone and ArcFace Head\n",
    "\"\"\"\n",
    "\n",
    "class JaguarReIDModel(nn.Module):\n",
    "    \"\"\"\n",
    "    Jaguar Re-Identification Model\n",
    "    \n",
    "    Architecture:\n",
    "    - Pretrained backbone (EfficientNet/ConvNeXt)\n",
    "    - Global Average Pooling\n",
    "    - Embedding layer with batch normalization\n",
    "    - ArcFace classification head\n",
    "    \"\"\"\n",
    "    def __init__(\n",
    "        self,\n",
    "        model_name: str = 'tf_efficientnet_b4_ns',\n",
    "        pretrained: bool = True,\n",
    "        embedding_dim: int = 512,\n",
    "        num_classes: int = 31,\n",
    "        arcface_s: float = 30.0,\n",
    "        arcface_m: float = 0.5,\n",
    "        dropout: float = 0.3\n",
    "    ):\n",
    "        super().__init__()\n",
    "        \n",
    "        # Backbone\n",
    "        self.backbone = timm.create_model(\n",
    "            model_name, \n",
    "            pretrained=pretrained, \n",
    "            num_classes=0,  # Remove classifier\n",
    "            global_pool='avg'\n",
    "        )\n",
    "        \n",
    "        # Get backbone output features\n",
    "        in_features = self.backbone.num_features\n",
    "        \n",
    "        # Embedding layers\n",
    "        self.embedding = nn.Sequential(\n",
    "            nn.Linear(in_features, embedding_dim),\n",
    "            nn.BatchNorm1d(embedding_dim),\n",
    "            nn.PReLU(),\n",
    "            nn.Dropout(dropout),\n",
    "        )\n",
    "        \n",
    "        # ArcFace head\n",
    "        self.arcface = ArcMarginProduct(\n",
    "            in_features=embedding_dim,\n",
    "            out_features=num_classes,\n",
    "            s=arcface_s,\n",
    "            m=arcface_m\n",
    "        )\n",
    "        \n",
    "        self.embedding_dim = embedding_dim\n",
    "        self.num_classes = num_classes\n",
    "        \n",
    "    def forward(self, x: torch.Tensor, labels: Optional[torch.Tensor] = None):\n",
    "        \"\"\"\n",
    "        Forward pass\n",
    "        \n",
    "        Args:\n",
    "            x: Input images [B, 3, H, W]\n",
    "            labels: Class labels [B] (required for training with ArcFace)\n",
    "            \n",
    "        Returns:\n",
    "            If labels provided: ArcFace logits for training\n",
    "            If no labels: Normalized embeddings for inference\n",
    "        \"\"\"\n",
    "        # Extract features\n",
    "        features = self.backbone(x)\n",
    "        \n",
    "        # Get embeddings\n",
    "        embeddings = self.embedding(features)\n",
    "        \n",
    "        if labels is not None:\n",
    "            # Training mode: return ArcFace logits\n",
    "            logits = self.arcface(embeddings, labels)\n",
    "            return logits, embeddings\n",
    "        else:\n",
    "            # Inference mode: return normalized embeddings\n",
    "            embeddings = F.normalize(embeddings, p=2, dim=1)\n",
    "            return embeddings\n",
    "    \n",
    "    def get_embedding(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        \"\"\"Extract normalized embeddings for inference\"\"\"\n",
    "        features = self.backbone(x)\n",
    "        embeddings = self.embedding(features)\n",
    "        embeddings = F.normalize(embeddings, p=2, dim=1)\n",
    "        return embeddings\n",
    "\n",
    "\n",
    "# Test model creation\n",
    "print(\"ðŸ—ï¸ Building model...\")\n",
    "model = JaguarReIDModel(\n",
    "    model_name=CFG.MODEL_NAME,\n",
    "    pretrained=CFG.PRETRAINED,\n",
    "    embedding_dim=CFG.EMBEDDING_DIM,\n",
    "    num_classes=CFG.NUM_CLASSES,\n",
    "    arcface_s=CFG.ARCFACE_S,\n",
    "    arcface_m=CFG.ARCFACE_M\n",
    ")\n",
    "\n",
    "# Count parameters\n",
    "total_params = sum(p.numel() for p in model.parameters())\n",
    "trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "print(f\"âœ… Model created successfully!\")\n",
    "print(f\"  Total parameters: {total_params:,}\")\n",
    "print(f\"  Trainable parameters: {trainable_params:,}\")\n",
    "print(f\"  Backbone: {CFG.MODEL_NAME}\")\n",
    "print(f\"  Embedding dim: {CFG.EMBEDDING_DIM}\")\n",
    "\n",
    "# Test forward pass\n",
    "model = model.to(DEVICE)\n",
    "dummy_input = torch.randn(2, 3, CFG.IMG_SIZE, CFG.IMG_SIZE).to(DEVICE)\n",
    "dummy_labels = torch.tensor([0, 1]).to(DEVICE)\n",
    "\n",
    "with torch.no_grad():\n",
    "    logits, embeddings = model(dummy_input, dummy_labels)\n",
    "    print(f\"\\n  Test forward pass:\")\n",
    "    print(f\"    Input shape: {dummy_input.shape}\")\n",
    "    print(f\"    Logits shape: {logits.shape}\")\n",
    "    print(f\"    Embeddings shape: {embeddings.shape}\")\n",
    "\n",
    "# Clean up\n",
    "del model, dummy_input, dummy_labels\n",
    "torch.cuda.empty_cache()\n",
    "gc.collect()\n",
    "```\n",
    "\n",
    "```python\n",
    "# =============================================================================\n",
    "# CELL 13: WEIGHTED SAMPLER FOR CLASS IMBALANCE\n",
    "# =============================================================================\n",
    "\"\"\"\n",
    "Create weighted sampler to handle class imbalance during training\n",
    "\"\"\"\n",
    "\n",
    "def create_weighted_sampler(labels: np.ndarray) -> WeightedRandomSampler:\n",
    "    \"\"\"\n",
    "    Create a weighted random sampler for balanced training\n",
    "    \n",
    "    Args:\n",
    "        labels: Array of class labels\n",
    "        \n",
    "    Returns:\n",
    "        WeightedRandomSampler instance\n",
    "    \"\"\"\n",
    "    class_counts = Counter(labels)\n",
    "    num_samples = len(labels)\n",
    "    \n",
    "    # Calculate weight for each class (inverse frequency)\n",
    "    class_weights = {cls: num_samples / count for cls, count in class_counts.items()}\n",
    "    \n",
    "    # Assign weight to each sample\n",
    "    sample_weights = [class_weights[label] for label in labels]\n",
    "    sample_weights = torch.tensor(sample_weights, dtype=torch.float)\n",
    "    \n",
    "    # Create sampler\n",
    "    sampler = WeightedRandomSampler(\n",
    "        weights=sample_weights,\n",
    "        num_samples=len(sample_weights),\n",
    "        replacement=True\n",
    "    )\n",
    "    \n",
    "    return sampler\n",
    "\n",
    "# Calculate class weights for focal loss\n",
    "def calculate_class_weights(labels: np.ndarray) -> torch.Tensor:\n",
    "    \"\"\"Calculate class weights based on inverse frequency\"\"\"\n",
    "    class_counts = Counter(labels)\n",
    "    total = len(labels)\n",
    "    num_classes = len(class_counts)\n",
    "    \n",
    "    weights = torch.zeros(num_classes)\n",
    "    for cls, count in class_counts.items():\n",
    "        weights[cls] = total / (num_classes * count)\n",
    "    \n",
    "    return weights\n",
    "\n",
    "# Display class balance info\n",
    "class_counts = train_df['label'].value_counts().sort_index()\n",
    "print(\"âš–ï¸ Class Balance Analysis:\")\n",
    "print(f\"  Most represented: {label_to_jaguar[class_counts.idxmax()]} ({class_counts.max()} images)\")\n",
    "print(f\"  Least represented: {label_to_jaguar[class_counts.idxmin()]} ({class_counts.min()} images)\")\n",
    "print(f\"  Imbalance ratio: {class_counts.max() / class_counts.min():.2f}x\")\n",
    "```\n",
    "\n",
    "```python\n",
    "# =============================================================================\n",
    "# CELL 14: TRAINING UTILITIES\n",
    "# =============================================================================\n",
    "\"\"\"\n",
    "Training helper functions\n",
    "\"\"\"\n",
    "\n",
    "class AverageMeter:\n",
    "    \"\"\"Computes and stores the average and current value\"\"\"\n",
    "    def __init__(self):\n",
    "        self.reset()\n",
    "        \n",
    "    def reset(self):\n",
    "        self.val = 0\n",
    "        self.avg = 0\n",
    "        self.sum = 0\n",
    "        self.count = 0\n",
    "        \n",
    "    def update(self, val, n=1):\n",
    "        self.val = val\n",
    "        self.sum += val * n\n",
    "        self.count += n\n",
    "        self.avg = self.sum / self.count\n",
    "\n",
    "\n",
    "def calculate_accuracy(logits: torch.Tensor, labels: torch.Tensor) -> float:\n",
    "    \"\"\"Calculate classification accuracy\"\"\"\n",
    "    preds = logits.argmax(dim=1)\n",
    "    correct = (preds == labels).sum().item()\n",
    "    return correct / len(labels)\n",
    "\n",
    "\n",
    "def save_checkpoint(model, optimizer, scheduler, epoch, fold, loss, path):\n",
    "    \"\"\"Save model checkpoint\"\"\"\n",
    "    checkpoint = {\n",
    "        'epoch': epoch,\n",
    "        'fold': fold,\n",
    "        'model_state_dict': model.state_dict(),\n",
    "        'optimizer_state_dict': optimizer.state_dict(),\n",
    "        'scheduler_state_dict': scheduler.state_dict() if scheduler else None,\n",
    "        'loss': loss,\n",
    "    }\n",
    "    torch.save(checkpoint, path)\n",
    "\n",
    "\n",
    "def load_checkpoint(model, path):\n",
    "    \"\"\"Load model checkpoint\"\"\"\n",
    "    checkpoint = torch.load(path, map_location=DEVICE)\n",
    "    model.load_state_dict(checkpoint['model_state_dict'])\n",
    "    return model, checkpoint['epoch'], checkpoint['loss']\n",
    "\n",
    "print(\"âœ… Training utilities defined!\")\n",
    "```\n",
    "\n",
    "```python\n",
    "# =============================================================================\n",
    "# CELL 15: TRAINING LOOP\n",
    "# =============================================================================\n",
    "\"\"\"\n",
    "Main training loop with mixed precision and gradient accumulation\n",
    "\"\"\"\n",
    "\n",
    "def train_one_epoch(\n",
    "    model: nn.Module,\n",
    "    train_loader: DataLoader,\n",
    "    optimizer: torch.optim.Optimizer,\n",
    "    criterion: nn.Module,\n",
    "    scheduler,\n",
    "    epoch: int,\n",
    "    device: torch.device,\n",
    "    scaler: GradScaler,\n",
    "    accumulation_steps: int = 1\n",
    ") -> Tuple[float, float]:\n",
    "    \"\"\"\n",
    "    Train for one epoch\n",
    "    \"\"\"\n",
    "    model.train()\n",
    "    \n",
    "    loss_meter = AverageMeter()\n",
    "    acc_meter = AverageMeter()\n",
    "    \n",
    "    pbar = tqdm(train_loader, desc=f'Train Epoch {epoch}')\n",
    "    \n",
    "    optimizer.zero_grad()\n",
    "    \n",
    "    for step, (images, labels) in enumerate(pbar):\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "        \n",
    "        # Mixed precision forward pass\n",
    "        with autocast(enabled=CFG.MIXED_PRECISION):\n",
    "            logits, embeddings = model(images, labels)\n",
    "            loss = criterion(logits, labels)\n",
    "            loss = loss / accumulation_steps\n",
    "        \n",
    "        # Backward pass with gradient scaling\n",
    "        scaler.scale(loss).backward()\n",
    "        \n",
    "        # Gradient accumulation\n",
    "        if (step + 1) % accumulation_steps == 0:\n",
    "            scaler.step(optimizer)\n",
    "            scaler.update()\n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            if scheduler is not None:\n",
    "                scheduler.step()\n",
    "        \n",
    "        # Calculate metrics\n",
    "        acc = calculate_accuracy(logits.detach(), labels)\n",
    "        \n",
    "        loss_meter.update(loss.item() * accumulation_steps, images.size(0))\n",
    "        acc_meter.update(acc, images.size(0))\n",
    "        \n",
    "        # Update progress bar\n",
    "        pbar.set_postfix({\n",
    "            'loss': f'{loss_meter.avg:.4f}',\n",
    "            'acc': f'{acc_meter.avg:.4f}',\n",
    "            'lr': f'{optimizer.param_groups[0][\"lr\"]:.2e}'\n",
    "        })\n",
    "    \n",
    "    return loss_meter.avg, acc_meter.avg\n",
    "\n",
    "\n",
    "@torch.no_grad()\n",
    "def validate(\n",
    "    model: nn.Module,\n",
    "    valid_loader: DataLoader,\n",
    "    criterion: nn.Module,\n",
    "    device: torch.device\n",
    ") -> Tuple[float, float]:\n",
    "    \"\"\"\n",
    "    Validate model\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    \n",
    "    loss_meter = AverageMeter()\n",
    "    acc_meter = AverageMeter()\n",
    "    \n",
    "    pbar = tqdm(valid_loader, desc='Validation')\n",
    "    \n",
    "    for images, labels in pbar:\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "        \n",
    "        with autocast(enabled=CFG.MIXED_PRECISION):\n",
    "            logits, embeddings = model(images, labels)\n",
    "            loss = criterion(logits, labels)\n",
    "        \n",
    "        acc = calculate_accuracy(logits.detach(), labels)\n",
    "        \n",
    "        loss_meter.update(loss.item(), images.size(0))\n",
    "        acc_meter.update(acc, images.size(0))\n",
    "        \n",
    "        pbar.set_postfix({\n",
    "            'loss': f'{loss_meter.avg:.4f}',\n",
    "            'acc': f'{acc_meter.avg:.4f}'\n",
    "        })\n",
    "    \n",
    "    return loss_meter.avg, acc_meter.avg\n",
    "\n",
    "print(\"âœ… Training loop defined!\")\n",
    "```\n",
    "\n",
    "```python\n",
    "# =============================================================================\n",
    "# CELL 16: CROSS-VALIDATION TRAINING\n",
    "# =============================================================================\n",
    "\"\"\"\n",
    "Full training pipeline with K-Fold Cross-Validation\n",
    "\"\"\"\n",
    "\n",
    "def train_fold(fold: int, train_df: pd.DataFrame):\n",
    "    \"\"\"\n",
    "    Train a single fold\n",
    "    \"\"\"\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"ðŸ”„ TRAINING FOLD {fold}\")\n",
    "    print(f\"{'='*60}\")\n",
    "    \n",
    "    # Split data\n",
    "    skf = StratifiedKFold(n_splits=CFG.N_FOLDS, shuffle=True, random_state=CFG.SEED)\n",
    "    \n",
    "    for fold_idx, (train_idx, valid_idx) in enumerate(skf.split(train_df, train_df['label'])):\n",
    "        if fold_idx == fold:\n",
    "            break\n",
    "    \n",
    "    train_data = train_df.iloc[train_idx].reset_index(drop=True)\n",
    "    valid_data = train_df.iloc[valid_idx].reset_index(drop=True)\n",
    "    \n",
    "    print(f\"  Train samples: {len(train_data)}\")\n",
    "    print(f\"  Valid samples: {len(valid_data)}\")\n",
    "    \n",
    "    # Create datasets\n",
    "    train_dataset = JaguarDataset(\n",
    "        train_data, \n",
    "        CFG.TRAIN_DIR,\n",
    "        transform=get_train_transforms(CFG.IMG_SIZE)\n",
    "    )\n",
    "    \n",
    "    valid_dataset = JaguarDataset(\n",
    "        valid_data,\n",
    "        CFG.TRAIN_DIR,\n",
    "        transform=get_valid_transforms(CFG.IMG_SIZE)\n",
    "    )\n",
    "    \n",
    "    # Create weighted sampler\n",
    "    sampler = create_weighted_sampler(train_data['label'].values)\n",
    "    \n",
    "    # Create dataloaders\n",
    "    train_loader = DataLoader(\n",
    "        train_dataset,\n",
    "        batch_size=CFG.BATCH_SIZE,\n",
    "        sampler=sampler,\n",
    "        num_workers=CFG.NUM_WORKERS,\n",
    "        pin_memory=True,\n",
    "        drop_last=True\n",
    "    )\n",
    "    \n",
    "    valid_loader = DataLoader(\n",
    "        valid_dataset,\n",
    "        batch_size=CFG.BATCH_SIZE * 2,\n",
    "        shuffle=False,\n",
    "        num_workers=CFG.NUM_WORKERS,\n",
    "        pin_memory=True,\n",
    "        drop_last=False\n",
    "    )\n",
    "    \n",
    "    # Initialize model\n",
    "    model = JaguarReIDModel(\n",
    "        model_name=CFG.MODEL_NAME,\n",
    "        pretrained=CFG.PRETRAINED,\n",
    "        embedding_dim=CFG.EMBEDDING_DIM,\n",
    "        num_classes=CFG.NUM_CLASSES,\n",
    "        arcface_s=CFG.ARCFACE_S,\n",
    "        arcface_m=CFG.ARCFACE_M\n",
    "    ).to(DEVICE)\n",
    "    \n",
    "    # Loss function with class weights\n",
    "    class_weights = calculate_class_weights(train_data['label'].values).to(DEVICE)\n",
    "    criterion = FocalLoss(gamma=2.0, alpha=class_weights)\n",
    "    \n",
    "    # Optimizer\n",
    "    optimizer = AdamW(\n",
    "        model.parameters(),\n",
    "        lr=CFG.LEARNING_RATE,\n",
    "        weight_decay=CFG.WEIGHT_DECAY\n",
    "    )\n",
    "    \n",
    "    # Scheduler\n",
    "    num_training_steps = len(train_loader) * CFG.EPOCHS\n",
    "    scheduler = OneCycleLR(\n",
    "        optimizer,\n",
    "        max_lr=CFG.LEARNING_RATE * 10,\n",
    "        total_steps=num_training_steps,\n",
    "        pct_start=0.1,\n",
    "        anneal_strategy='cos'\n",
    "    )\n",
    "    \n",
    "    # Mixed precision scaler\n",
    "    scaler = GradScaler(enabled=CFG.MIXED_PRECISION)\n",
    "    \n",
    "    # Training history\n",
    "    history = {\n",
    "        'train_loss': [],\n",
    "        'train_acc': [],\n",
    "        'valid_loss': [],\n",
    "        'valid_acc': [],\n",
    "        'lr': []\n",
    "    }\n",
    "    \n",
    "    best_loss = float('inf')\n",
    "    best_acc = 0\n",
    "    \n",
    "    # Training loop\n",
    "    for epoch in range(1, CFG.EPOCHS + 1):\n",
    "        print(f\"\\nðŸ“… Epoch {epoch}/{CFG.EPOCHS}\")\n",
    "        \n",
    "        # Train\n",
    "        train_loss, train_acc = train_one_epoch(\n",
    "            model, train_loader, optimizer, criterion,\n",
    "            scheduler, epoch, DEVICE, scaler, CFG.ACCUMULATION_STEPS\n",
    "        )\n",
    "        \n",
    "        # Validate\n",
    "        valid_loss, valid_acc = validate(\n",
    "            model, valid_loader, criterion, DEVICE\n",
    "        )\n",
    "        \n",
    "        # Log history\n",
    "        history['train_loss'].append(train_loss)\n",
    "        history['train_acc'].append(train_acc)\n",
    "        history['valid_loss'].append(valid_loss)\n",
    "        history['valid_acc'].append(valid_acc)\n",
    "        history['lr'].append(optimizer.param_groups[0]['lr'])\n",
    "        \n",
    "        print(f\"  Train Loss: {train_loss:.4f} | Train Acc: {train_acc:.4f}\")\n",
    "        print(f\"  Valid Loss: {valid_loss:.4f} | Valid Acc: {valid_acc:.4f}\")\n",
    "        \n",
    "        # Save best model\n",
    "        if valid_loss < best_loss:\n",
    "            best_loss = valid_loss\n",
    "            best_acc = valid_acc\n",
    "            save_checkpoint(\n",
    "                model, optimizer, scheduler, epoch, fold, valid_loss,\n",
    "                CFG.OUTPUT_DIR / f'best_model_fold{fold}.pth'\n",
    "            )\n",
    "            print(f\"  âœ… Best model saved! (Loss: {best_loss:.4f}, Acc: {best_acc:.4f})\")\n",
    "        \n",
    "        # Early stopping check (optional)\n",
    "        if CFG.DEBUG and epoch >= 3:\n",
    "            print(\"  âš ï¸ Debug mode: stopping early\")\n",
    "            break\n",
    "    \n",
    "    print(f\"\\nðŸ† Fold {fold} Complete!\")\n",
    "    print(f\"  Best Valid Loss: {best_loss:.4f}\")\n",
    "    print(f\"  Best Valid Acc: {best_acc:.4f}\")\n",
    "    \n",
    "    # Clean up\n",
    "    del model, optimizer, scheduler, train_loader, valid_loader\n",
    "    torch.cuda.empty_cache()\n",
    "    gc.collect()\n",
    "    \n",
    "    return history\n",
    "\n",
    "# Train selected folds\n",
    "all_histories = {}\n",
    "for fold in CFG.SELECTED_FOLDS:\n",
    "    history = train_fold(fold, train_df)\n",
    "    all_histories[fold] = history\n",
    "```\n",
    "\n",
    "```python\n",
    "# =============================================================================\n",
    "# CELL 17: TRAINING VISUALIZATION\n",
    "# =============================================================================\n",
    "\"\"\"\n",
    "Visualize training progress with loss and accuracy curves\n",
    "\"\"\"\n",
    "\n",
    "def plot_training_history(histories: Dict[int, dict]):\n",
    "    \"\"\"\n",
    "    ðŸ“Š Plot 11-13: Training History Curves\n",
    "    \"\"\"\n",
    "    fig, axes = plt.subplots(2, 2, figsize=(16, 12))\n",
    "    \n",
    "    colors = plt.cm.Set2(np.linspace(0, 1, len(histories)))\n",
    "    \n",
    "    for idx, (fold, history) in enumerate(histories.items()):\n",
    "        color = colors[idx]\n",
    "        epochs = range(1, len(history['train_loss']) + 1)\n",
    "        \n",
    "        # ============================================================================\n",
    "        # PLOT 11: Training Loss Curve\n",
    "        # ============================================================================\n",
    "        axes[0, 0].plot(epochs, history['train_loss'], \n",
    "                       label=f'Fold {fold} Train', color=color, linestyle='-', linewidth=2)\n",
    "        axes[0, 0].plot(epochs, history['valid_loss'], \n",
    "                       label=f'Fold {fold} Valid', color=color, linestyle='--', linewidth=2)\n",
    "    \n",
    "    axes[0, 0].set_xlabel('Epoch', fontsize=12)\n",
    "    axes[0, 0].set_ylabel('Loss', fontsize=12)\n",
    "    axes[0, 0].set_title('ðŸ“Š Plot 11: Training & Validation Loss', fontsize=14, fontweight='bold')\n",
    "    axes[0, 0].legend()\n",
    "    axes[0, 0].grid(True, alpha=0.3)\n",
    "    \n",
    "    # ============================================================================\n",
    "    # PLOT 12: Accuracy Curve\n",
    "    # ============================================================================\n",
    "    for idx, (fold, history) in enumerate(histories.items()):\n",
    "        color = colors[idx]\n",
    "        epochs = range(1, len(history['train_acc']) + 1)\n",
    "        \n",
    "        axes[0, 1].plot(epochs, history['train_acc'], \n",
    "                       label=f'Fold {fold} Train', color=color, linestyle='-', linewidth=2)\n",
    "        axes[0, 1].plot(epochs, history['valid_acc'], \n",
    "                       label=f'Fold {fold} Valid', color=color, linestyle='--', linewidth=2)\n",
    "    \n",
    "    axes[0, 1].set_xlabel('Epoch', fontsize=12)\n",
    "    axes[0, 1].set_ylabel('Accuracy', fontsize=12)\n",
    "    axes[0, 1].set_title('ðŸ“Š Plot 12: Training & Validation Accuracy', fontsize=14, fontweight='bold')\n",
    "    axes[0, 1].legend()\n",
    "    axes[0, 1].grid(True, alpha=0.3)\n",
    "    axes[0, 1].set_ylim([0, 1])\n",
    "    \n",
    "    # ============================================================================\n",
    "    # PLOT 13: Learning Rate Schedule\n",
    "    # ============================================================================\n",
    "    for idx, (fold, history) in enumerate(histories.items()):\n",
    "        color = colors[idx]\n",
    "        epochs = range(1, len(history['lr']) + 1)\n",
    "        \n",
    "        axes[1, 0].plot(epochs, history['lr'], \n",
    "                       label=f'Fold {fold}', color=color, linewidth=2)\n",
    "    \n",
    "    axes[1, 0].set_xlabel('Epoch', fontsize=12)\n",
    "    axes[1, 0].set_ylabel('Learning Rate', fontsize=12)\n",
    "    axes[1, 0].set_title('ðŸ“Š Plot 13: Learning Rate Schedule', fontsize=14, fontweight='bold')\n",
    "    axes[1, 0].legend()\n",
    "    axes[1, 0].grid(True, alpha=0.3)\n",
    "    axes[1, 0].set_yscale('log')\n",
    "    \n",
    "    # ============================================================================\n",
    "    # PLOT 14: Loss vs Accuracy\n",
    "    # ============================================================================\n",
    "    for idx, (fold, history) in enumerate(histories.items()):\n",
    "        color = colors[idx]\n",
    "        axes[1, 1].scatter(history['valid_loss'], history['valid_acc'], \n",
    "                          c=[color] * len(history['valid_loss']), \n",
    "                          label=f'Fold {fold}', alpha=0.7, s=50)\n",
    "    \n",
    "    axes[1, 1].set_xlabel('Validation Loss', fontsize=12)\n",
    "    axes[1, 1].set_ylabel('Validation Accuracy', fontsize=12)\n",
    "    axes[1, 1].set_title('ðŸ“Š Plot 14: Loss vs Accuracy Trade-off', fontsize=14, fontweight='bold')\n",
    "    axes[1, 1].legend()\n",
    "    axes[1, 1].grid(True, alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig(CFG.OUTPUT_DIR / 'training_history.png', dpi=150, bbox_inches='tight')\n",
    "    plt.show()\n",
    "\n",
    "# Plot training history\n",
    "if all_histories:\n",
    "    plot_training_history(all_histories)\n",
    "```\n",
    "\n",
    "```python\n",
    "# =============================================================================\n",
    "# CELL 18: INFERENCE - EXTRACT EMBEDDINGS\n",
    "# =============================================================================\n",
    "\"\"\"\n",
    "Extract embeddings for test images\n",
    "\"\"\"\n",
    "\n",
    "@torch.no_grad()\n",
    "def extract_embeddings(\n",
    "    model: nn.Module,\n",
    "    dataloader: DataLoader,\n",
    "    device: torch.device\n",
    ") -> Tuple[np.ndarray, List[str]]:\n",
    "    \"\"\"\n",
    "    Extract embeddings for all images in dataloader\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    \n",
    "    all_embeddings = []\n",
    "    all_filenames = []\n",
    "    \n",
    "    pbar = tqdm(dataloader, desc='Extracting embeddings')\n",
    "    \n",
    "    for images, filenames in pbar:\n",
    "        images = images.to(device)\n",
    "        \n",
    "        with autocast(enabled=CFG.MIXED_PRECISION):\n",
    "            embeddings = model.get_embedding(images)\n",
    "        \n",
    "        all_embeddings.append(embeddings.cpu().numpy())\n",
    "        all_filenames.extend(filenames)\n",
    "    \n",
    "    embeddings = np.vstack(all_embeddings)\n",
    "    \n",
    "    return embeddings, all_filenames\n",
    "\n",
    "\n",
    "def load_best_model(fold: int = 0) -> nn.Module:\n",
    "    \"\"\"Load the best model from a specific fold\"\"\"\n",
    "    model = JaguarReIDModel(\n",
    "        model_name=CFG.MODEL_NAME,\n",
    "        pretrained=False,\n",
    "        embedding_dim=CFG.EMBEDDING_DIM,\n",
    "        num_classes=CFG.NUM_CLASSES,\n",
    "        arcface_s=CFG.ARCFACE_S,\n",
    "        arcface_m=CFG.ARCFACE_M\n",
    "    ).to(DEVICE)\n",
    "    \n",
    "    checkpoint_path = CFG.OUTPUT_DIR / f'best_model_fold{fold}.pth'\n",
    "    if checkpoint_path.exists():\n",
    "        model, _, _ = load_checkpoint(model, checkpoint_path)\n",
    "        print(f\"âœ… Loaded model from {checkpoint_path}\")\n",
    "    else:\n",
    "        print(f\"âš ï¸ No checkpoint found at {checkpoint_path}\")\n",
    "    \n",
    "    return model\n",
    "\n",
    "\n",
    "# Get unique test images\n",
    "test_images = list(set(test_df['query_image'].tolist() + test_df['gallery_image'].tolist()))\n",
    "test_images = sorted(test_images)\n",
    "print(f\"ðŸ“Š Total unique test images: {len(test_images)}\")\n",
    "\n",
    "# Create test dataset and dataloader\n",
    "test_dataset = JaguarTestDataset(\n",
    "    image_files=test_images,\n",
    "    img_dir=CFG.TEST_DIR,\n",
    "    transform=get_test_transforms(CFG.IMG_SIZE)\n",
    ")\n",
    "\n",
    "test_loader = DataLoader(\n",
    "    test_dataset,\n",
    "    batch_size=CFG.BATCH_SIZE * 2,\n",
    "    shuffle=False,\n",
    "    num_workers=CFG.NUM_WORKERS,\n",
    "    pin_memory=True\n",
    ")\n",
    "\n",
    "# Load best model and extract embeddings\n",
    "model = load_best_model(fold=CFG.SELECTED_FOLDS[0])\n",
    "test_embeddings, test_filenames = extract_embeddings(model, test_loader, DEVICE)\n",
    "\n",
    "# Create filename to embedding mapping\n",
    "embedding_dict = dict(zip(test_filenames, test_embeddings))\n",
    "\n",
    "print(f\"\\nâœ… Embeddings extracted!\")\n",
    "print(f\"  Shape: {test_embeddings.shape}\")\n",
    "print(f\"  Files: {len(test_filenames)}\")\n",
    "```\n",
    "\n",
    "```python\n",
    "# =============================================================================\n",
    "# CELL 19: EMBEDDING VISUALIZATION\n",
    "# =============================================================================\n",
    "\"\"\"\n",
    "Visualize embeddings using t-SNE and UMAP\n",
    "\"\"\"\n",
    "\n",
    "# Also extract train embeddings for visualization\n",
    "train_dataset_viz = JaguarDataset(\n",
    "    train_df,\n",
    "    CFG.TRAIN_DIR,\n",
    "    transform=get_valid_transforms(CFG.IMG_SIZE)\n",
    ")\n",
    "\n",
    "train_loader_viz = DataLoader(\n",
    "    train_dataset_viz,\n",
    "    batch_size=CFG.BATCH_SIZE * 2,\n",
    "    shuffle=False,\n",
    "    num_workers=CFG.NUM_WORKERS,\n",
    "    pin_memory=True\n",
    ")\n",
    "\n",
    "# Extract train embeddings\n",
    "@torch.no_grad()\n",
    "def extract_train_embeddings(model, dataloader, device):\n",
    "    \"\"\"Extract embeddings and labels for training data\"\"\"\n",
    "    model.eval()\n",
    "    \n",
    "    all_embeddings = []\n",
    "    all_labels = []\n",
    "    \n",
    "    for images, labels in tqdm(dataloader, desc='Extracting train embeddings'):\n",
    "        images = images.to(device)\n",
    "        embeddings = model.get_embedding(images)\n",
    "        all_embeddings.append(embeddings.cpu().numpy())\n",
    "        all_labels.extend(labels.numpy())\n",
    "    \n",
    "    return np.vstack(all_embeddings), np.array(all_labels)\n",
    "\n",
    "train_embeddings, train_labels = extract_train_embeddings(model, train_loader_viz, DEVICE)\n",
    "\n",
    "# t-SNE visualization\n",
    "print(\"\\nðŸ”„ Computing t-SNE...\")\n",
    "tsne = TSNE(n_components=2, random_state=CFG.SEED, perplexity=30, n_iter=1000)\n",
    "train_tsne = tsne.fit_transform(train_embeddings)\n",
    "\n",
    "# Plot t-SNE\n",
    "fig, axes = plt.subplots(1, 2, figsize=(20, 8))\n",
    "\n",
    "# ============================================================================\n",
    "# PLOT 15: t-SNE Embedding Visualization\n",
    "# ============================================================================\n",
    "scatter = axes[0].scatter(\n",
    "    train_tsne[:, 0], train_tsne[:, 1],\n",
    "    c=train_labels, cmap='tab20', alpha=0.7, s=30\n",
    ")\n",
    "axes[0].set_xlabel('t-SNE Dimension 1', fontsize=12)\n",
    "axes[0].set_ylabel('t-SNE Dimension 2', fontsize=12)\n",
    "axes[0].set_title('ðŸ“Š Plot 15: t-SNE Visualization of Jaguar Embeddings', \n",
    "                  fontsize=14, fontweight='bold')\n",
    "\n",
    "# Add colorbar\n",
    "cbar = plt.colorbar(scatter, ax=axes[0])\n",
    "cbar.set_label('Jaguar ID', fontsize=11)\n",
    "\n",
    "# ============================================================================\n",
    "# PLOT 16: t-SNE with Selected Jaguars Highlighted\n",
    "# ============================================================================\n",
    "# Highlight a few specific jaguars\n",
    "selected_jaguars = [0, 5, 10, 15, 20]\n",
    "colors_selected = ['red', 'blue', 'green', 'orange', 'purple']\n",
    "\n",
    "axes[1].scatter(train_tsne[:, 0], train_tsne[:, 1], c='lightgray', alpha=0.3, s=20)\n",
    "\n",
    "for jaguar_id, color in zip(selected_jaguars, colors_selected):\n",
    "    mask = train_labels == jaguar_id\n",
    "    jaguar_name = label_to_jaguar.get(jaguar_id, f'ID {jaguar_id}')\n",
    "    axes[1].scatter(\n",
    "        train_tsne[mask, 0], train_tsne[mask, 1],\n",
    "        c=color, label=jaguar_name, s=50, alpha=0.8, edgecolors='black'\n",
    "    )\n",
    "\n",
    "axes[1].set_xlabel('t-SNE Dimension 1', fontsize=12)\n",
    "axes[1].set_ylabel('t-SNE Dimension 2', fontsize=12)\n",
    "axes[1].set_title('ðŸ“Š Plot 16: Selected Jaguars Highlighted', fontsize=14, fontweight='bold')\n",
    "axes[1].legend(loc='upper right')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(CFG.OUTPUT_DIR / 'embedding_visualization.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "```\n",
    "\n",
    "```python\n",
    "# =============================================================================\n",
    "# CELL 20: SIMILARITY COMPUTATION\n",
    "# =============================================================================\n",
    "\"\"\"\n",
    "Compute pairwise similarity scores for test image pairs\n",
    "\"\"\"\n",
    "\n",
    "def compute_cosine_similarity(emb1: np.ndarray, emb2: np.ndarray) -> float:\n",
    "    \"\"\"Compute cosine similarity between two embeddings\"\"\"\n",
    "    return np.dot(emb1, emb2) / (np.linalg.norm(emb1) * np.linalg.norm(emb2))\n",
    "\n",
    "\n",
    "def compute_all_similarities(\n",
    "    test_df: pd.DataFrame,\n",
    "    embedding_dict: Dict[str, np.ndarray]\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Compute similarity scores for all test pairs\n",
    "    \"\"\"\n",
    "    print(\"ðŸ”„ Computing pairwise similarities...\")\n",
    "    \n",
    "    similarities = []\n",
    "    \n",
    "    for idx, row in tqdm(test_df.iterrows(), total=len(test_df)):\n",
    "        query_img = row['query_image']\n",
    "        gallery_img = row['gallery_image']\n",
    "        \n",
    "        if query_img in embedding_dict and gallery_img in embedding_dict:\n",
    "            emb1 = embedding_dict[query_img]\n",
    "            emb2 = embedding_dict[gallery_img]\n",
    "            sim = compute_cosine_similarity(emb1, emb2)\n",
    "            # Convert to probability-like score (0 to 1)\n",
    "            sim = (sim + 1) / 2  # Shift from [-1,1] to [0,1]\n",
    "        else:\n",
    "            sim = 0.5  # Default for missing images\n",
    "        \n",
    "        similarities.append(sim)\n",
    "    \n",
    "    test_df['similarity'] = similarities\n",
    "    \n",
    "    return test_df\n",
    "\n",
    "\n",
    "# Compute similarities\n",
    "test_df_with_sim = compute_all_similarities(test_df.copy(), embedding_dict)\n",
    "\n",
    "print(\"\\nâœ… Similarity computation complete!\")\n",
    "print(f\"  Total pairs: {len(test_df_with_sim):,}\")\n",
    "print(f\"  Similarity stats:\")\n",
    "print(f\"    Min: {test_df_with_sim['similarity'].min():.4f}\")\n",
    "print(f\"    Max: {test_df_with_sim['similarity'].max():.4f}\")\n",
    "print(f\"    Mean: {test_df_with_sim['similarity'].mean():.4f}\")\n",
    "print(f\"    Std: {test_df_with_sim['similarity'].std():.4f}\")\n",
    "```\n",
    "\n",
    "```python\n",
    "# =============================================================================\n",
    "# CELL 21: SIMILARITY DISTRIBUTION VISUALIZATION\n",
    "# =============================================================================\n",
    "\"\"\"\n",
    "Visualize the distribution of similarity scores\n",
    "\"\"\"\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(16, 6))\n",
    "\n",
    "# ============================================================================\n",
    "# PLOT 17: Similarity Score Distribution\n",
    "# ============================================================================\n",
    "axes[0].hist(test_df_with_sim['similarity'], bins=50, color='steelblue', \n",
    "             edgecolor='black', alpha=0.7)\n",
    "axes[0].axvline(test_df_with_sim['similarity'].mean(), color='red', \n",
    "               linestyle='--', linewidth=2, label=f\"Mean: {test_df_with_sim['similarity'].mean():.3f}\")\n",
    "axes[0].axvline(test_df_with_sim['similarity'].median(), color='green',\n",
    "               linestyle='--', linewidth=2, label=f\"Median: {test_df_with_sim['similarity'].median():.3f}\")\n",
    "axes[0].set_xlabel('Similarity Score', fontsize=12)\n",
    "axes[0].set_ylabel('Frequency', fontsize=12)\n",
    "axes[0].set_title('ðŸ“Š Plot 17: Distribution of Similarity Scores', fontsize=14, fontweight='bold')\n",
    "axes[0].legend()\n",
    "axes[0].grid(True, alpha=0.3)\n",
    "\n",
    "# ============================================================================\n",
    "# PLOT 18: Similarity Score Box Plot by Score Range\n",
    "# ============================================================================\n",
    "# Create score bins\n",
    "test_df_with_sim['score_bin'] = pd.cut(test_df_with_sim['similarity'], \n",
    "                                        bins=[0, 0.2, 0.4, 0.6, 0.8, 1.0],\n",
    "                                        labels=['0-0.2', '0.2-0.4', '0.4-0.6', '0.6-0.8', '0.8-1.0'])\n",
    "score_bin_counts = test_df_with_sim['score_bin'].value_counts().sort_index()\n",
    "\n",
    "axes[1].bar(score_bin_counts.index.astype(str), score_bin_counts.values, \n",
    "           color=plt.cm.RdYlGn(np.linspace(0.2, 0.8, 5)), edgecolor='black')\n",
    "axes[1].set_xlabel('Similarity Score Range', fontsize=12)\n",
    "axes[1].set_ylabel('Number of Pairs', fontsize=12)\n",
    "axes[1].set_title('ðŸ“Š Plot 18: Pairs Distribution by Similarity Range', fontsize=14, fontweight='bold')\n",
    "\n",
    "# Add count labels\n",
    "for i, (idx, val) in enumerate(zip(score_bin_counts.index, score_bin_counts.values)):\n",
    "    axes[1].text(i, val + 500, f'{val:,}', ha='center', fontsize=10)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(CFG.OUTPUT_DIR / 'similarity_distribution.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "```\n",
    "\n",
    "```python\n",
    "# =============================================================================\n",
    "# CELL 22: TOP MATCHES VISUALIZATION\n",
    "# =============================================================================\n",
    "\"\"\"\n",
    "Visualize top matching pairs and potential hard negatives\n",
    "\"\"\"\n",
    "\n",
    "def visualize_top_matches(df: pd.DataFrame, img_dir: Path, n_pairs: int = 5):\n",
    "    \"\"\"\n",
    "    ðŸ“Š Plot 19: Top Matching Pairs\n",
    "    Show the most similar image pairs\n",
    "    \"\"\"\n",
    "    # Sort by similarity\n",
    "    top_matches = df.nlargest(n_pairs, 'similarity')\n",
    "    \n",
    "    fig, axes = plt.subplots(n_pairs, 2, figsize=(12, 4*n_pairs))\n",
    "    fig.suptitle('ðŸ“Š Plot 19: Top Matching Pairs (Highest Similarity)', \n",
    "                 fontsize=16, fontweight='bold', y=1.02)\n",
    "    \n",
    "    for i, (_, row) in enumerate(top_matches.iterrows()):\n",
    "        query_path = img_dir / row['query_image']\n",
    "        gallery_path = img_dir / row['gallery_image']\n",
    "        \n",
    "        if query_path.exists():\n",
    "            img1 = load_image(query_path)\n",
    "            axes[i, 0].imshow(img1)\n",
    "        axes[i, 0].set_title(f\"Query: {row['query_image']}\", fontsize=10)\n",
    "        axes[i, 0].axis('off')\n",
    "        \n",
    "        if gallery_path.exists():\n",
    "            img2 = load_image(gallery_path)\n",
    "            axes[i, 1].imshow(img2)\n",
    "        axes[i, 1].set_title(f\"Gallery: {row['gallery_image']}\\nSimilarity: {row['similarity']:.4f}\", \n",
    "                            fontsize=10)\n",
    "        axes[i, 1].axis('off')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig(CFG.OUTPUT_DIR / 'top_matches.png', dpi=150, bbox_inches='tight')\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def visualize_low_matches(df: pd.DataFrame, img_dir: Path, n_pairs: int = 5):\n",
    "    \"\"\"\n",
    "    ðŸ“Š Plot 20: Lowest Matching Pairs (Likely Different Jaguars)\n",
    "    \"\"\"\n",
    "    low_matches = df.nsmallest(n_pairs, 'similarity')\n",
    "    \n",
    "    fig, axes = plt.subplots(n_pairs, 2, figsize=(12, 4*n_pairs))\n",
    "    fig.suptitle('ðŸ“Š Plot 20: Lowest Matching Pairs (Likely Different Jaguars)', \n",
    "                 fontsize=16, fontweight='bold', y=1.02)\n",
    "    \n",
    "    for i, (_, row) in enumerate(low_matches.iterrows()):\n",
    "        query_path = img_dir / row['query_image']\n",
    "        gallery_path = img_dir / row['gallery_image']\n",
    "        \n",
    "        if query_path.exists():\n",
    "            img1 = load_image(query_path)\n",
    "            axes[i, 0].imshow(img1)\n",
    "        axes[i, 0].set_title(f\"Query: {row['query_image']}\", fontsize=10)\n",
    "        axes[i, 0].axis('off')\n",
    "        \n",
    "        if gallery_path.exists():\n",
    "            img2 = load_image(gallery_path)\n",
    "            axes[i, 1].imshow(img2)\n",
    "        axes[i, 1].set_title(f\"Gallery: {row['gallery_image']}\\nSimilarity: {row['similarity']:.4f}\", \n",
    "                            fontsize=10)\n",
    "        axes[i, 1].axis('off')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig(CFG.OUTPUT_DIR / 'low_matches.png', dpi=150, bbox_inches='tight')\n",
    "    plt.show()\n",
    "\n",
    "# Visualize matches\n",
    "visualize_top_matches(test_df_with_sim, CFG.TEST_DIR, n_pairs=5)\n",
    "visualize_low_matches(test_df_with_sim, CFG.TEST_DIR, n_pairs=5)\n",
    "```\n",
    "\n",
    "```python\n",
    "# =============================================================================\n",
    "# CELL 23: GENERATE SUBMISSION FILE\n",
    "# =============================================================================\n",
    "\"\"\"\n",
    "Generate the final submission file\n",
    "\"\"\"\n",
    "\n",
    "# Create submission dataframe\n",
    "submission = pd.DataFrame({\n",
    "    'row_id': test_df_with_sim['row_id'],\n",
    "    'similarity': test_df_with_sim['similarity']\n",
    "})\n",
    "\n",
    "# Ensure proper formatting\n",
    "submission['row_id'] = submission['row_id'].astype(int)\n",
    "submission['similarity'] = submission['similarity'].astype(float)\n",
    "\n",
    "# Clip values to valid range\n",
    "submission['similarity'] = submission['similarity'].clip(0.0, 1.0)\n",
    "\n",
    "# Sort by row_id\n",
    "submission = submission.sort_values('row_id').reset_index(drop=True)\n",
    "\n",
    "# Save submission\n",
    "submission_path = CFG.OUTPUT_DIR / 'submission.csv'\n",
    "submission.to_csv(submission_path, index=False)\n",
    "\n",
    "print(\"âœ… Submission file generated!\")\n",
    "print(f\"  Path: {submission_path}\")\n",
    "print(f\"  Shape: {submission.shape}\")\n",
    "print(f\"\\nðŸ“Š Submission Preview:\")\n",
    "display(submission.head(10))\n",
    "display(submission.tail(10))\n",
    "\n",
    "# Validate submission\n",
    "print(f\"\\nðŸ” Submission Validation:\")\n",
    "print(f\"  Row IDs match: {(submission['row_id'] == test_df['row_id']).all()}\")\n",
    "print(f\"  Valid range: {(submission['similarity'] >= 0).all() and (submission['similarity'] <= 1).all()}\")\n",
    "print(f\"  No NaN values: {submission['similarity'].notna().all()}\")\n",
    "```\n",
    "\n",
    "```python\n",
    "# =============================================================================\n",
    "# CELL 24: FINAL SUMMARY\n",
    "# =============================================================================\n",
    "\"\"\"\n",
    "Print final summary of the solution\n",
    "\"\"\"\n",
    "\n",
    "print(\"=\" * 70)\n",
    "print(\"ðŸ† JAGUAR RE-IDENTIFICATION CHALLENGE - SOLUTION SUMMARY\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "summary = f\"\"\"\n",
    "ðŸ“Š DATASET STATISTICS:\n",
    "   â€¢ Training images: {len(train_df):,}\n",
    "   â€¢ Unique jaguars: {train_df['ground_truth'].nunique()}\n",
    "   â€¢ Test image pairs: {len(test_df):,}\n",
    "   â€¢ Unique test images: {len(test_images)}\n",
    "\n",
    "ðŸ—ï¸ MODEL ARCHITECTURE:\n",
    "   â€¢ Backbone: {CFG.MODEL_NAME}\n",
    "   â€¢ Embedding dimension: {CFG.EMBEDDING_DIM}\n",
    "   â€¢ Loss function: ArcFace + Focal Loss\n",
    "   â€¢ ArcFace scale (s): {CFG.ARCFACE_S}\n",
    "   â€¢ ArcFace margin (m): {CFG.ARCFACE_M}\n",
    "\n",
    "âš™ï¸ TRAINING CONFIGURATION:\n",
    "   â€¢ Image size: {CFG.IMG_SIZE}x{CFG.IMG_SIZE}\n",
    "   â€¢ Batch size: {CFG.BATCH_SIZE}\n",
    "   â€¢ Epochs: {CFG.EPOCHS}\n",
    "   â€¢ Learning rate: {CFG.LEARNING_RATE}\n",
    "   â€¢ Folds trained: {CFG.SELECTED_FOLDS}\n",
    "\n",
    "ðŸ“ˆ OUTPUT FILES:\n",
    "   â€¢ Model checkpoints: {CFG.OUTPUT_DIR}/best_model_fold*.pth\n",
    "   â€¢ Training plots: {CFG.OUTPUT_DIR}/*.png\n",
    "   â€¢ Submission: {CFG.OUTPUT_DIR}/submission.csv\n",
    "\n",
    "ðŸ“‹ SUBMISSION STATISTICS:\n",
    "   â€¢ Total predictions: {len(submission):,}\n",
    "   â€¢ Similarity range: [{submission['similarity'].min():.4f}, {submission['similarity'].max():.4f}]\n",
    "   â€¢ Mean similarity: {submission['similarity'].mean():.4f}\n",
    "\"\"\"\n",
    "\n",
    "print(summary)\n",
    "print(\"=\" * 70)\n",
    "print(\"âœ… Notebook execution complete!\")\n",
    "print(\"=\" * 70)\n",
    "```\n",
    "\n",
    "```python\n",
    "# =============================================================================\n",
    "# CELL 25: PLOTS SUMMARY\n",
    "# =============================================================================\n",
    "\"\"\"\n",
    "Summary of all visualization plots generated\n",
    "\"\"\"\n",
    "\n",
    "plots_summary = \"\"\"\n",
    "â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—\n",
    "â•‘                       ðŸ“Š PLOTS SUMMARY                                      â•‘\n",
    "â• â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•£\n",
    "â•‘                                                                            â•‘\n",
    "â•‘  EXPLORATORY DATA ANALYSIS (EDA):                                          â•‘\n",
    "â•‘  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•‘\n",
    "â•‘  1.  Class Distribution Bar Plot        - Images per jaguar identity      â•‘\n",
    "â•‘  2.  Class Distribution Pie Chart       - Top 10 jaguars percentage       â•‘\n",
    "â•‘  3.  Dataset Statistics                 - Key metrics summary             â•‘\n",
    "â•‘  4.  Distribution Histogram             - Images per class histogram      â•‘\n",
    "â•‘  5.  Sample Images Grid                 - Examples for each jaguar        â•‘\n",
    "â•‘  6.  Image Width Distribution           - Width histogram                 â•‘\n",
    "â•‘  7.  Image Height Distribution          - Height histogram                â•‘\n",
    "â•‘  8.  Aspect Ratio Distribution          - Width/Height ratio              â•‘\n",
    "â•‘  9.  File Size Distribution             - Image file sizes                â•‘\n",
    "â•‘  10. Augmentation Samples               - Before/after augmentation       â•‘\n",
    "â•‘                                                                            â•‘\n",
    "â•‘  TRAINING VISUALIZATION:                                                   â•‘\n",
    "â•‘  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•‘\n",
    "â•‘  11. Training Loss Curve                - Loss over epochs                â•‘\n",
    "â•‘  12. Accuracy Curve                     - Train/valid accuracy            â•‘\n",
    "â•‘  13. Learning Rate Schedule             - LR changes over training        â•‘\n",
    "â•‘  14. Loss vs Accuracy Trade-off         - Scatter plot                    â•‘\n",
    "â•‘                                                                            â•‘\n",
    "â•‘  EMBEDDING ANALYSIS:                                                       â•‘\n",
    "â•‘  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•‘\n",
    "â•‘  15. t-SNE Visualization                - 2D embedding projection         â•‘\n",
    "â•‘  16. Selected Jaguars Highlighted       - Specific classes highlighted    â•‘\n",
    "â•‘                                                                            â•‘\n",
    "â•‘  INFERENCE RESULTS:                                                        â•‘\n",
    "â•‘  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•‘\n",
    "â•‘  17. Similarity Score Distribution      - Histogram of predictions        â•‘\n",
    "â•‘  18. Pairs by Similarity Range          - Binned distribution             â•‘\n",
    "â•‘  19. Top Matching Pairs                 - Highest similarity examples     â•‘\n",
    "â•‘  20. Lowest Matching Pairs              - Lowest similarity examples      â•‘\n",
    "â•‘                                                                            â•‘\n",
    "â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "\"\"\"\n",
    "\n",
    "print(plots_summary)\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## ðŸ“ Author Information Template\n",
    "\n",
    "```markdown\n",
    "# ðŸ‘¨â€ðŸ’» About the Author\n",
    "\n",
    "## [YOUR FULL NAME]\n",
    "**Machine Learning Engineer | Data Scientist | AI Researcher**\n",
    "\n",
    "### ðŸ“« Contact Information\n",
    "- ðŸ“§ **Email:** your.email@example.com\n",
    "- ðŸ“ **Location:** Your City, Country\n",
    "\n",
    "### ðŸ”— Social Networks & Profiles\n",
    "\n",
    "| Platform | Link | Description |\n",
    "|----------|------|-------------|\n",
    "| ðŸ’¼ LinkedIn | [linkedin.com/in/your-profile](https://linkedin.com/in/your-profile) | Professional network |\n",
    "| ðŸ™ GitHub | [github.com/your-username](https://github.com/your-username) | Code repositories |\n",
    "| ðŸ“Š Kaggle | [kaggle.com/your-username](https://kaggle.com/your-username) | Competition profile |\n",
    "| ðŸ¦ Twitter/X | [twitter.com/your-handle](https://twitter.com/your-handle) | Tech updates |\n",
    "| ðŸŒ Portfolio | [your-website.com](https://your-website.com) | Personal website |\n",
    "| ðŸ“ Medium | [medium.com/@your-username](https://medium.com/@your-username) | Technical blog |\n",
    "| ðŸŽ“ Google Scholar | [scholar.google.com/citations?user=YOUR_ID](https://scholar.google.com) | Publications |\n",
    "| ðŸ“¹ YouTube | [youtube.com/@your-channel](https://youtube.com/@your-channel) | Tutorial videos |\n",
    "\n",
    "### ðŸ† Achievements\n",
    "- [List your relevant achievements]\n",
    "- [Kaggle competitions, rankings, etc.]\n",
    "- [Publications, certifications, etc.]\n",
    "\n",
    "### ðŸ’¡ Expertise\n",
    "- Computer Vision & Image Classification\n",
    "- Deep Learning & Neural Networks\n",
    "- Wildlife Conservation Technology\n",
    "- Re-Identification Systems\n",
    "- Metric Learning\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## ðŸŽ¯ Quick Start Guide\n",
    "\n",
    "To run this notebook:\n",
    "\n",
    "1. **Set up your environment:**\n",
    "```bash\n",
    "pip install torch torchvision timm albumentations pytorch-metric-learning scikit-learn pandas numpy matplotlib seaborn tqdm opencv-python-headless pillow\n",
    "```\n",
    "\n",
    "2. **Update the paths in CFG class** to point to your data directory\n",
    "\n",
    "3. **Run cells sequentially** - each cell is designed to work independently\n",
    "\n",
    "4. **For quick testing**, set `CFG.DEBUG = True` to run with fewer epochs\n",
    "\n",
    "---\n",
    "\n",
    "This comprehensive notebook provides a professional, end-to-end solution for the Jaguar Re-Identification Challenge! ðŸ†"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
